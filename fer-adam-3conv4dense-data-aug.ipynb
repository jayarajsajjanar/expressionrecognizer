{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This IPython notebook trains the model with 3 convolutional layers, 4 densely connected layers including the final output softmax layer. Each of the 3 convolutional layers are followed by by a batch normalization layer and a maxpooling layer.\n",
    "We use adam optimization during training.\n",
    "This particular implementation uses data augmentation along with dropout for regularization optimization for training.\n",
    "\n",
    "We generate additional 9 images for each training image. \n",
    "\n",
    "All the layers except the output layer use ReLU activation function to preserve the non-linearity in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from numpy import unique, ndarray, mean, std\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_pickle\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "vector_encoding = True\n",
    "img_height, img_width = 48, 48\n",
    "filepath = \"adam-data-aug.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_pickle('dataset/input_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.Training\n",
    "validate = data.Validation\n",
    "test = data.Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_validate, y_validate = validate\n",
    "x_test, y_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = x - mean(x, axis = 1).reshape((-1,1))\n",
    "    x = (x - mean(x, axis = 0)) / std(x, axis = 0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = normalize(x_train)\n",
    "x_validate = normalize(x_validate)\n",
    "x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=45,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='wrap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "new_x = []\n",
    "new_y = []\n",
    "for x,y in zip(x_train,y_train): \n",
    "    x = np.reshape(x, (1,48, 48,1))\n",
    "    count = 8\n",
    "#     i=1\n",
    "    \n",
    "    images_flow = datagen.flow(x, batch_size=1)\n",
    "    for i, new_images in enumerate(images_flow):\n",
    "        \n",
    "        new_x.append(np.reshape(new_images[0], (2304,)))\n",
    "        new_y.append(y)\n",
    "        \n",
    "        if i >= count:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.asarray(new_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = np.asarray(new_x)\n",
    "new_y = np.asarray(new_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_train,new_x),axis=0)\n",
    "y_train = np.concatenate((y_train,new_y),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = x_train.shape[0]\n",
    "num_validate_samples = x_validate.shape[0]\n",
    "num_test_samples = x_test.shape[0]\n",
    "num_labels = unique(y_train).shape[0]\n",
    "if(vector_encoding):\n",
    "    y_train = keras.utils.to_categorical(y_train, num_labels)\n",
    "    y_validate = keras.utils.to_categorical(y_validate, num_labels)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if backend.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(num_train_samples, 1, img_height, img_width)\n",
    "    x_validate = x_validate.reshape(num_validate_samples, 1, img_height, img_width)\n",
    "    x_test = x_test.reshape(num_test_samples, 1, img_height, img_width)\n",
    "    input_shape = (1, img_height, img_width)\n",
    "else:\n",
    "    x_train = x_train.reshape(num_train_samples, img_height, img_width, 1)\n",
    "    x_validate = x_validate.reshape(num_validate_samples, img_height, img_width, 1)\n",
    "    x_test = x_test.reshape(num_test_samples, img_height, img_width, 1)\n",
    "    input_shape = (img_height, img_width, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation = 'relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(128, kernel_size=(3,3), activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath, \n",
    "                             monitor='val_loss', \n",
    "                             verbose=0, \n",
    "                             save_best_only=True, \n",
    "                             mode='auto', \n",
    "                             period = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=x_train,\n",
    "                    y=y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_validate, y_validate),\n",
    "                    shuffle=True,\n",
    "                    callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, accuracy) = model.evaluate(x_test,\n",
    "                                  y_test,\n",
    "                                  batch_size=batch_size,\n",
    "                                  verbose=1)\n",
    "print(\"Loss: %.4f\"%(loss))\n",
    "print(\"Accuract: %.4f\"%(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,1)\n",
    "plt.legend(['Train','Validation'], loc='lower right')\n",
    "plt.savefig('Accuracy_adam_data_aug_batchnorm.png')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0,2.5)\n",
    "plt.legend(['Train','Validation'], loc='upper right')\n",
    "plt.savefig('Loss_adam_data_aug_batchnorm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "import pydot\n",
    "import graphviz\n",
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='adam_data_aug_batchnorm.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
